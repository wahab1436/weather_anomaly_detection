{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Alert EDA\n",
    "## Exploratory Data Analysis for Weather Anomaly Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "df = pd.read_csv('../data/processed/weather_alerts_processed.csv')\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"\\nColumns:\\n{df.columns.tolist()}\")\n",
    "print(f\"\\nData types:\\n{df.dtypes.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic statistics\n",
    "print(\"First few rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nBasic info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nDescriptive statistics:\")\n",
    "display(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alert Type Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'alert_type' in df.columns:\n",
    "    alert_counts = df['alert_type'].value_counts()\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Bar chart\n",
    "    alert_counts.plot(kind='bar', ax=ax1, color='steelblue')\n",
    "    ax1.set_title('Alert Type Distribution', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Alert Type', fontsize=12)\n",
    "    ax1.set_ylabel('Count', fontsize=12)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Pie chart\n",
    "    alert_counts.plot(kind='pie', ax=ax2, autopct='%1.1f%%', startangle=90)\n",
    "    ax2.set_title('Alert Type Proportion', fontsize=14, fontweight='bold')\n",
    "    ax2.set_ylabel('')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nAlert type counts:\\n{alert_counts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'timestamp' in df.columns:\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "    df['month'] = df['timestamp'].dt.month\n",
    "    \n",
    "    # Daily alerts\n",
    "    daily_alerts = df.groupby('date').size()\n",
    "    \n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(14, 12))\n",
    "    \n",
    "    # Time series\n",
    "    daily_alerts.plot(ax=ax1, color='darkred', linewidth=2)\n",
    "    ax1.set_title('Daily Alert Count Over Time', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Date', fontsize=12)\n",
    "    ax1.set_ylabel('Number of Alerts', fontsize=12)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Hourly distribution\n",
    "    hourly_counts = df['hour'].value_counts().sort_index()\n",
    "    hourly_counts.plot(kind='bar', ax=ax2, color='teal')\n",
    "    ax2.set_title('Hourly Distribution of Alerts', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Hour of Day', fontsize=12)\n",
    "    ax2.set_ylabel('Count', fontsize=12)\n",
    "    \n",
    "    # Day of week distribution\n",
    "    day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    dow_counts = df['day_of_week'].value_counts().sort_index()\n",
    "    dow_counts.index = [day_names[i] for i in dow_counts.index]\n",
    "    dow_counts.plot(kind='bar', ax=ax3, color='purple')\n",
    "    ax3.set_title('Day of Week Distribution', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Day of Week', fontsize=12)\n",
    "    ax3.set_ylabel('Count', fontsize=12)\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nAverage daily alerts: {daily_alerts.mean():.1f}\")\n",
    "    print(f\"Peak hour: {hourly_counts.idxmax()}:00 ({hourly_counts.max()} alerts)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regional Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'region' in df.columns:\n",
    "    region_counts = df['region'].value_counts()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    region_counts.plot(kind='bar', ax=ax, color='forestgreen')\n",
    "    ax.set_title('Alert Distribution by Region', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Region', fontsize=12)\n",
    "    ax.set_ylabel('Number of Alerts', fontsize=12)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nTop 5 regions:\\n{region_counts.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text length analysis\n",
    "if 'description' in df.columns:\n",
    "    df['description_length'] = df['description'].apply(lambda x: len(str(x)))\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Histogram\n",
    "    df['description_length'].hist(bins=50, ax=ax1, color='coral', edgecolor='black')\n",
    "    ax1.set_title('Description Length Distribution', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Description Length (characters)', fontsize=12)\n",
    "    ax1.set_ylabel('Frequency', fontsize=12)\n",
    "    \n",
    "    # Box plot\n",
    "    df.boxplot(column='description_length', ax=ax2, vert=False)\n",
    "    ax2.set_title('Description Length Box Plot', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Description Length (characters)', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nDescription length statistics:\")\n",
    "    print(f\"Mean: {df['description_length'].mean():.1f}\")\n",
    "    print(f\"Median: {df['description_length'].median():.1f}\")\n",
    "    print(f\"Std: {df['description_length'].std():.1f}\")\n",
    "    print(f\"Min: {df['description_length'].min()}\")\n",
    "    print(f\"Max: {df['description_length'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns for correlation\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "if len(numeric_cols) > 1:\n",
    "    # Limit to top columns for readability\n",
    "    top_cols = numeric_cols[:10]\n",
    "    \n",
    "    corr_matrix = df[top_cols].corr()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "                center=0, square=True, linewidths=0.5, ax=ax)\n",
    "    \n",
    "    ax.set_title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop correlations:\")\n",
    "    # Flatten correlation matrix and get top absolute correlations\n",
    "    corr_pairs = corr_matrix.unstack()\n",
    "    sorted_pairs = corr_pairs.sort_values(key=abs, ascending=False)\n",
    "    \n",
    "    # Remove self-correlations and duplicates\n",
    "    unique_pairs = pd.DataFrame(sorted_pairs).reset_index()\n",
    "    unique_pairs.columns = ['Feature1', 'Feature2', 'Correlation']\n",
    "    unique_pairs = unique_pairs[unique_pairs['Feature1'] != unique_pairs['Feature2']]\n",
    "    unique_pairs = unique_pairs.iloc[::2]  # Take every other to avoid duplicates\n",
    "    \n",
    "    display(unique_pairs.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Values': missing_values,\n",
    "    'Percentage': missing_percentage\n",
    "})\n",
    "\n",
    "missing_df = missing_df[missing_df['Missing Values'] > 0].sort_values('Percentage', ascending=False)\n",
    "\n",
    "if not missing_df.empty:\n",
    "    print(\"Columns with missing values:\")\n",
    "    display(missing_df)\n",
    "    \n",
    "    # Visualize missing values\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    missing_df['Percentage'].plot(kind='bar', ax=ax, color='orange')\n",
    "    ax.set_title('Missing Values Percentage by Column', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Column', fontsize=12)\n",
    "    ax.set_ylabel('Percentage Missing', fontsize=12)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No missing values found in the dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load anomaly results if available\n",
    "try:\n",
    "    anomaly_df = pd.read_csv('../data/output/anomaly_results.csv', index_col=0)\n",
    "    anomaly_df.index = pd.to_datetime(anomaly_df.index)\n",
    "    \n",
    "    if 'is_anomaly' in anomaly_df.columns:\n",
    "        print(f\"Anomaly data loaded: {anomaly_df.shape}\")\n",
    "        print(f\"\\nAnomalies detected: {anomaly_df['is_anomaly'].sum()} ({anomaly_df['is_anomaly'].sum() / len(anomaly_df) * 100:.1f}%)\")\n",
    "        \n",
    "        # Plot anomalies\n",
    "        fig, ax = plt.subplots(figsize=(14, 6))\n",
    "        \n",
    "        # Plot time series\n",
    "        if 'total_alerts' in anomaly_df.columns:\n",
    "            ax.plot(anomaly_df.index, anomaly_df['total_alerts'], \n",
    "                    color='blue', linewidth=1, label='Daily Alerts')\n",
    "        \n",
    "        # Highlight anomalies\n",
    "        anomalies = anomaly_df[anomaly_df['is_anomaly']]\n",
    "        if not anomalies.empty and 'total_alerts' in anomalies.columns:\n",
    "            ax.scatter(anomalies.index, anomalies['total_alerts'], \n",
    "                      color='red', s=100, zorder=5, label='Anomalies')\n",
    "        \n",
    "        ax.set_title('Daily Alerts with Anomaly Detection', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Date', fontsize=12)\n",
    "        ax.set_ylabel('Number of Alerts', fontsize=12)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"Anomaly results not found. Run anomaly detection first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EDA SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nDataset Overview:\")\n",
    "print(f\"- Total records: {len(df):,}\")\n",
    "print(f\"- Total features: {len(df.columns)}\")\n",
    "print(f\"- Time range: {df['timestamp'].min() if 'timestamp' in df.columns else 'N/A'} to {df['timestamp'].max() if 'timestamp' in df.columns else 'N/A'}\")\n",
    "\n",
    "print(f\"\\nKey Findings:\")\n",
    "\n",
    "if 'alert_type' in df.columns:\n",
    "    top_alert = df['alert_type'].value_counts().index[0]\n",
    "    print(f\"- Most common alert type: {top_alert}\")\n",
    "\n",
    "if 'region' in df.columns:\n",
    "    top_region = df['region'].value_counts().index[0]\n",
    "    print(f\"- Most active region: {top_region}\")\n",
    "\n",
    "if 'hour' in df.columns:\n",
    "    peak_hour = df['hour'].value_counts().index[0]\n",
    "    print(f\"- Peak alert hour: {peak_hour}:00\")\n",
    "\n",
    "print(f\"\\nData Quality:\")\n",
    "total_missing = df.isnull().sum().sum()\n",
    "total_cells = df.shape[0] * df.shape[1]\n",
    "print(f\"- Missing values: {total_missing:,} ({total_missing/total_cells*100:.1f}%)\")\n",
    "print(f\"- Duplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
